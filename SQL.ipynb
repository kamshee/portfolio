{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Examples using SQLAlchemy in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: Demonstrate the use of SQLAlchemy to make SQL queries.\n",
    "\n",
    "SQLAlchemy features:\n",
    "- Supported platforms: Python, Jython, Pypy\n",
    "- Various SQL databases are supported including dialects for SQLite, Postgresql, MySQL, Oracle, MS-SQL, Firebird, Sybase and others, most of which support multiple DBAPIs.\n",
    "- Reference: https://www.sqlalchemy.org/features.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:24:10.455027Z",
     "start_time": "2018-10-27T03:24:10.451690Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import (create_engine, MetaData, Table, select, and_,\n",
    "or_, not_, between, func, case, cast, Float)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. Explore database before querying using SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T05:09:24.730528Z",
     "start_time": "2018-10-26T05:09:24.718012Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names:  ['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'sqlite_sequence', 'sqlite_stat1', 'tracks']\n"
     ]
    }
   ],
   "source": [
    "# check table names\n",
    "engine = create_engine('sqlite:///chinook.db')\n",
    "connection = engine.connect()\n",
    "print('Table names: ', engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T03:01:06.355994Z",
     "start_time": "2018-10-26T03:01:06.346721Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('employees', MetaData(bind=None), Column('EmployeeId', INTEGER(), table=<employees>, primary_key=True, nullable=False), Column('LastName', NVARCHAR(length=20), table=<employees>, nullable=False), Column('FirstName', NVARCHAR(length=20), table=<employees>, nullable=False), Column('Title', NVARCHAR(length=30), table=<employees>), Column('ReportsTo', INTEGER(), ForeignKey('employees.EmployeeId'), table=<employees>), Column('BirthDate', DATETIME(), table=<employees>), Column('HireDate', DATETIME(), table=<employees>), Column('Address', NVARCHAR(length=70), table=<employees>), Column('City', NVARCHAR(length=40), table=<employees>), Column('State', NVARCHAR(length=40), table=<employees>), Column('Country', NVARCHAR(length=40), table=<employees>), Column('PostalCode', NVARCHAR(length=10), table=<employees>), Column('Phone', NVARCHAR(length=24), table=<employees>), Column('Fax', NVARCHAR(length=24), table=<employees>), Column('Email', NVARCHAR(length=60), table=<employees>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# view column names and data types\n",
    "metadata = MetaData()\n",
    "employees = Table('employees', metadata, autoload=True, \n",
    "               autoload_with=engine)\n",
    "print(repr(employees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Basic workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T01:45:04.300378Z",
     "start_time": "2018-10-27T01:45:04.272227Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "   EmployeeId LastName FirstName                Title  ReportsTo  \\\n",
      "0           1    Adams    Andrew      General Manager        NaN   \n",
      "1           2  Edwards     Nancy        Sales Manager        1.0   \n",
      "2           3  Peacock      Jane  Sales Support Agent        2.0   \n",
      "3           4     Park  Margaret  Sales Support Agent        2.0   \n",
      "4           5  Johnson     Steve  Sales Support Agent        2.0   \n",
      "\n",
      "             BirthDate             HireDate              Address      City  \\\n",
      "0  1962-02-18 00:00:00  2002-08-14 00:00:00  11120 Jasper Ave NW  Edmonton   \n",
      "1  1958-12-08 00:00:00  2002-05-01 00:00:00         825 8 Ave SW   Calgary   \n",
      "2  1973-08-29 00:00:00  2002-04-01 00:00:00        1111 6 Ave SW   Calgary   \n",
      "3  1947-09-19 00:00:00  2003-05-03 00:00:00     683 10 Street SW   Calgary   \n",
      "4  1965-03-03 00:00:00  2003-10-17 00:00:00         7727B 41 Ave   Calgary   \n",
      "\n",
      "  State Country PostalCode              Phone                Fax  \\\n",
      "0    AB  Canada    T5K 2N1  +1 (780) 428-9482  +1 (780) 428-3457   \n",
      "1    AB  Canada    T2P 2T3  +1 (403) 262-3443  +1 (403) 262-3322   \n",
      "2    AB  Canada    T2P 5M5  +1 (403) 262-3443  +1 (403) 262-6712   \n",
      "3    AB  Canada    T2P 5G3  +1 (403) 263-4423  +1 (403) 263-4289   \n",
      "4    AB  Canada    T3B 1Y7   1 (780) 836-9987   1 (780) 836-9543   \n",
      "\n",
      "                      Email  \n",
      "0    andrew@chinookcorp.com  \n",
      "1     nancy@chinookcorp.com  \n",
      "2      jane@chinookcorp.com  \n",
      "3  margaret@chinookcorp.com  \n",
      "4     steve@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "# Create the database engine\n",
    "engine = create_engine('sqlite:///chinook.db')\n",
    "\n",
    "# Use context manager to connect to the engine and \n",
    "# skip manually closing the connection\n",
    "with engine.connect() as con:\n",
    "    # query the database by selecting columns\n",
    "    rs = con.execute(\"SELECT * FROM Employees\")\n",
    "    # save as pandas dataframe and select 20 rows with size argument\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    # set column names\n",
    "    df.columns = rs.keys()\n",
    "    \n",
    "# EDA\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Load directly into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T21:17:21.474854Z",
     "start_time": "2018-10-26T21:17:21.450457Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe dimensions:  (8, 15)\n",
      "   EmployeeId LastName FirstName                Title  ReportsTo  \\\n",
      "0           1    Adams    Andrew      General Manager        NaN   \n",
      "1           2  Edwards     Nancy        Sales Manager        1.0   \n",
      "2           3  Peacock      Jane  Sales Support Agent        2.0   \n",
      "3           4     Park  Margaret  Sales Support Agent        2.0   \n",
      "4           5  Johnson     Steve  Sales Support Agent        2.0   \n",
      "\n",
      "             BirthDate             HireDate              Address      City  \\\n",
      "0  1962-02-18 00:00:00  2002-08-14 00:00:00  11120 Jasper Ave NW  Edmonton   \n",
      "1  1958-12-08 00:00:00  2002-05-01 00:00:00         825 8 Ave SW   Calgary   \n",
      "2  1973-08-29 00:00:00  2002-04-01 00:00:00        1111 6 Ave SW   Calgary   \n",
      "3  1947-09-19 00:00:00  2003-05-03 00:00:00     683 10 Street SW   Calgary   \n",
      "4  1965-03-03 00:00:00  2003-10-17 00:00:00         7727B 41 Ave   Calgary   \n",
      "\n",
      "  State Country PostalCode              Phone                Fax  \\\n",
      "0    AB  Canada    T5K 2N1  +1 (780) 428-9482  +1 (780) 428-3457   \n",
      "1    AB  Canada    T2P 2T3  +1 (403) 262-3443  +1 (403) 262-3322   \n",
      "2    AB  Canada    T2P 5M5  +1 (403) 262-3443  +1 (403) 262-6712   \n",
      "3    AB  Canada    T2P 5G3  +1 (403) 263-4423  +1 (403) 263-4289   \n",
      "4    AB  Canada    T3B 1Y7   1 (780) 836-9987   1 (780) 836-9543   \n",
      "\n",
      "                      Email  \n",
      "0    andrew@chinookcorp.com  \n",
      "1     nancy@chinookcorp.com  \n",
      "2      jane@chinookcorp.com  \n",
      "3  margaret@chinookcorp.com  \n",
      "4     steve@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///chinook.db')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM Employees\", engine)\n",
    "\n",
    "print('dataframe dimensions: ', df.shape)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. SQLAlchemy queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.1 Execute a Select statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T02:07:40.739894Z",
     "start_time": "2018-10-27T02:07:40.734050Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT employees.\"EmployeeId\", employees.\"LastName\", employees.\"FirstName\", employees.\"Title\", employees.\"ReportsTo\", employees.\"BirthDate\", employees.\"HireDate\", employees.\"Address\", employees.\"City\", employees.\"State\", employees.\"Country\", employees.\"PostalCode\", employees.\"Phone\", employees.\"Fax\", employees.\"Email\" \n",
      "FROM employees \n",
      "\n",
      "[(1, 'Adams', 'Andrew', 'General Manager', None, datetime.datetime(1962, 2, 18, 0, 0), datetime.datetime(2002, 8, 14, 0, 0), '11120 Jasper Ave NW', 'Edmonton', 'AB', 'Canada', 'T5K 2N1', '+1 (780) 428-9482', '+1 (780) 428-3457', 'andrew@chinookcorp.com'), (2, 'Edwards', 'Nancy', 'Sales Manager', 1, datetime.datetime(1958, 12, 8, 0, 0), datetime.datetime(2002, 5, 1, 0, 0), '825 8 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 2T3', '+1 (403) 262-3443', '+1 (403) 262-3322', 'nancy@chinookcorp.com'), (3, 'Peacock', 'Jane', 'Sales Support Agent', 2, datetime.datetime(1973, 8, 29, 0, 0), datetime.datetime(2002, 4, 1, 0, 0), '1111 6 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 5M5', '+1 (403) 262-3443', '+1 (403) 262-6712', 'jane@chinookcorp.com'), (4, 'Park', 'Margaret', 'Sales Support Agent', 2, datetime.datetime(1947, 9, 19, 0, 0), datetime.datetime(2003, 5, 3, 0, 0), '683 10 Street SW', 'Calgary', 'AB', 'Canada', 'T2P 5G3', '+1 (403) 263-4423', '+1 (403) 263-4289', 'margaret@chinookcorp.com'), (5, 'Johnson', 'Steve', 'Sales Support Agent', 2, datetime.datetime(1965, 3, 3, 0, 0), datetime.datetime(2003, 10, 17, 0, 0), '7727B 41 Ave', 'Calgary', 'AB', 'Canada', 'T3B 1Y7', '1 (780) 836-9987', '1 (780) 836-9543', 'steve@chinookcorp.com'), (6, 'Mitchell', 'Michael', 'IT Manager', 1, datetime.datetime(1973, 7, 1, 0, 0), datetime.datetime(2003, 10, 17, 0, 0), '5827 Bowness Road NW', 'Calgary', 'AB', 'Canada', 'T3B 0C5', '+1 (403) 246-9887', '+1 (403) 246-9899', 'michael@chinookcorp.com'), (7, 'King', 'Robert', 'IT Staff', 6, datetime.datetime(1970, 5, 29, 0, 0), datetime.datetime(2004, 1, 2, 0, 0), '590 Columbia Boulevard West', 'Lethbridge', 'AB', 'Canada', 'T1K 5N8', '+1 (403) 456-9986', '+1 (403) 456-8485', 'robert@chinookcorp.com'), (8, 'Callahan', 'Laura', 'IT Staff', 6, datetime.datetime(1968, 1, 9, 0, 0), datetime.datetime(2004, 3, 4, 0, 0), '923 7 ST NW', 'Lethbridge', 'AB', 'Canada', 'T1H 1Y8', '+1 (403) 467-3351', '+1 (403) 467-8772', 'laura@chinookcorp.com')]\n"
     ]
    }
   ],
   "source": [
    "# Build select statement for employees table: stmt\n",
    "stmt = select([employees])\n",
    "\n",
    "# Print the emitted statement to see the SQL emitted\n",
    "print(stmt, '\\n')\n",
    "\n",
    "# Execute the statement and print the results\n",
    "print(connection.execute(stmt).fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.2 Filter with Where clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T05:15:20.825935Z",
     "start_time": "2018-10-26T05:15:20.816254Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrew 1\n",
      "Nancy 2\n",
      "Jane 3\n",
      "Margaret 4\n",
      "Steve 5\n",
      "Michael 6\n",
      "Robert 7\n",
      "Laura 8\n"
     ]
    }
   ],
   "source": [
    "# Example using Where clause\n",
    "employees = Table('employees', metadata, autoload=True, \n",
    "                  autoload_with=engine)\n",
    "stmt = select([employees])\n",
    "stmt = stmt.where(employees.columns.Country == 'Canada')\n",
    "results = connection.execute(stmt).fetchall()\n",
    "for result in results:\n",
    "    print(result.FirstName, result.EmployeeId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 5.3 Filter with Where clause and Or conjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T01:57:23.166192Z",
     "start_time": "2018-10-27T01:57:23.158769Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago Frank Ralston\n",
      "London Emma Jones\n",
      "London Phil Hughes\n"
     ]
    }
   ],
   "source": [
    "# Example using Where and Or\n",
    "# conjunctions\n",
    "from sqlalchemy import or_\n",
    "customers = Table('customers', metadata, autoload=True, \n",
    "                  autoload_with=engine)\n",
    "stmt = select([customers])\n",
    "stmt = stmt.where(or_(customers.columns.City == 'Chicago',\n",
    "                     customers.columns.City == 'London'\n",
    "                     )\n",
    "                 )\n",
    "# loop over the ResultProxy and print city, customer first and last name\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.City, result.FirstName, result.LastName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 5.4 Counting distinct values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:05:53.239656Z",
     "start_time": "2018-10-27T03:05:53.232917Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# Query to count the distinct city values\n",
    "stmt = select([func.count(customers.columns.City.distinct())])\n",
    "\n",
    "# Execute the query and store the scalar result\n",
    "distinct_city_count = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the distinct cities\n",
    "print(distinct_city_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 5.5 Counting unique emails grouped by Country with a descriptive label for the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:13:36.509898Z",
     "start_time": "2018-10-27T03:13:36.497587Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Argentina', 1), ('Australia', 1), ('Austria', 1), ('Belgium', 1), ('Brazil', 5), ('Canada', 8), ('Chile', 1), ('Czech Republic', 2), ('Denmark', 1), ('Finland', 1), ('France', 5), ('Germany', 4), ('Hungary', 1), ('India', 2), ('Ireland', 1), ('Italy', 1), ('Netherlands', 1), ('Norway', 1), ('Poland', 1), ('Portugal', 2), ('Spain', 1), ('Sweden', 1), ('USA', 13), ('United Kingdom', 3)]\n"
     ]
    }
   ],
   "source": [
    "stmt = select([customers.columns.Country,\n",
    "              func.count(customers.columns.Email).label('email_count')])\n",
    "stmt = stmt.group_by(customers.columns.Country)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6. Convert results into dataframe and visualize using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:16:58.826921Z",
     "start_time": "2018-10-27T03:16:58.819387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country  email_count\n",
      "0        Argentina            1\n",
      "1        Australia            1\n",
      "2          Austria            1\n",
      "3          Belgium            1\n",
      "4           Brazil            5\n",
      "5           Canada            8\n",
      "6            Chile            1\n",
      "7   Czech Republic            2\n",
      "8          Denmark            1\n",
      "9          Finland            1\n",
      "10          France            5\n",
      "11         Germany            4\n",
      "12         Hungary            1\n",
      "13           India            2\n",
      "14         Ireland            1\n",
      "15           Italy            1\n",
      "16     Netherlands            1\n",
      "17          Norway            1\n",
      "18          Poland            1\n",
      "19        Portugal            2\n",
      "20           Spain            1\n",
      "21          Sweden            1\n",
      "22             USA           13\n",
      "23  United Kingdom            3\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame(results)\n",
    "# Set column names\n",
    "df.columns = results[0].keys()\n",
    "# Print the Dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:22:29.053185Z",
     "start_time": "2018-10-27T03:22:28.844588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b5f5ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.plot.bar()\n",
    "df.plot.bar('Country','email_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Automatic Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Hierarchical Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Dealing with large results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Creating and Manipulating my own databases and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T05:09:24.730528Z",
     "start_time": "2018-10-26T05:09:24.718012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names:  ['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'sqlite_sequence', 'sqlite_stat1', 'tracks']\n"
     ]
    }
   ],
   "source": [
    "# check table names\n",
    "engine = create_engine('sqlite:///chinook.db')\n",
    "connection = engine.connect()\n",
    "print('Table names: ', engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T03:07:39.450166Z",
     "start_time": "2018-10-27T03:07:39.428097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe dimensions:  (59, 13)\n",
      "   CustomerId  FirstName     LastName  \\\n",
      "0           1       Luís    Gonçalves   \n",
      "1           2     Leonie       Köhler   \n",
      "2           3   François     Tremblay   \n",
      "3           4      Bjørn       Hansen   \n",
      "4           5  František  Wichterlová   \n",
      "\n",
      "                                            Company  \\\n",
      "0  Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "1                                              None   \n",
      "2                                              None   \n",
      "3                                              None   \n",
      "4                                  JetBrains s.r.o.   \n",
      "\n",
      "                           Address                 City State         Country  \\\n",
      "0  Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP          Brazil   \n",
      "1          Theodor-Heuss-Straße 34            Stuttgart  None         Germany   \n",
      "2                1498 rue Bélanger             Montréal    QC          Canada   \n",
      "3                 Ullevålsveien 14                 Oslo  None          Norway   \n",
      "4                    Klanova 9/506               Prague  None  Czech Republic   \n",
      "\n",
      "  PostalCode               Phone                 Fax  \\\n",
      "0  12227-000  +55 (12) 3923-5555  +55 (12) 3923-5566   \n",
      "1      70174    +49 0711 2842222                None   \n",
      "2    H2G 1A7   +1 (514) 721-4711                None   \n",
      "3       0171     +47 22 44 22 22                None   \n",
      "4      14700    +420 2 4172 5555    +420 2 4172 5555   \n",
      "\n",
      "                      Email  SupportRepId  \n",
      "0      luisg@embraer.com.br             3  \n",
      "1     leonekohler@surfeu.de             5  \n",
      "2       ftremblay@gmail.com             3  \n",
      "3     bjorn.hansen@yahoo.no             4  \n",
      "4  frantisekw@jetbrains.com             4  \n"
     ]
    }
   ],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///chinook.db')\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM customers\", engine)\n",
    "\n",
    "print('dataframe dimensions: ', df.shape)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Advanced SQLAlchemy Queries\n",
    "Calculating Values in a Query\n",
    "\n",
    "Math Operators\n",
    "- addition + \n",
    "- subtraction - \n",
    "- multiplication *\n",
    "- division /\n",
    "- modulus %\n",
    "- Work differently on different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Calculating Difference\n",
    "- notice wrapping expression with () and then labeling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference\n",
    "stmt = select([census.columns.age,\n",
    "              (census.columns.pop2008-\n",
    "              census.columns.pop2000).label('pop_change')\n",
    "              ])\n",
    "# group by age\n",
    "stmt = stmt.group_by(census.columns.age)\n",
    "# order by pop_change\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "# return top 5 results\n",
    "stmt = stmt.limit(5)\n",
    "# execute the statement\n",
    "results = connection.execute(stmt).fetchall()\n",
    "# print\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Case Statement\n",
    "- notice wrapping expression with () and then labeling it\n",
    "- used to treat data differently based on a condition\n",
    "- accepts a list of conditions to match and a column to return if the condition matches\n",
    "- the list of conditions ends with an else clause to determine what to do when a record doesn't match any prior conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case example\n",
    "from sqlalchemy import case\n",
    "\n",
    "stmt = select([\n",
    "    func.sum(\n",
    "        case([\n",
    "            (census.columns.state == 'New york',\n",
    "             census.columns.pop2008)\n",
    "    ], else_=0))\n",
    "])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cast Statement\n",
    "- converts data to another type\n",
    "- use for converting\n",
    "    - integers to floats for division\n",
    "    - strings to dates and times\n",
    "- accepts a column or expression and the target Type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Percentage Example - Case and Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import case, cast, Float\n",
    "# calculate a percentage, note: convert to float type\n",
    "stmt = select([\n",
    "    (func.sum(\n",
    "        case([\n",
    "            (census.columns.state == 'New york',\n",
    "             census.columns.pop2008)\n",
    "        ], else_=0)) /\n",
    "     cast(func.sum(census.columns.pop2008),\n",
    "          Float) * 100).label('ny_percent')\n",
    "])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Connecting to a MySQL Database\n",
    "- pymysql database driver for MySQL database\n",
    "\n",
    "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the pymysql database driver, which, like psycopg2 for PostgreSQL, you have to install prior to use.\n",
    "\n",
    "This connection string is going to start with 'mysql+pymysql://', indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the 'username:password' combo. Next, you specify the host and port with the following '@host:port/'. Finally, you wrap up the connection string with the 'database_name'.\n",
    "\n",
    "Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!\n",
    "\n",
    "Create an engine to the census database by concatenating the following strings and passing them to create_engine():\n",
    "- 'mysql+pymysql://' (the dialect and driver).\n",
    "- 'student:datacamp' (the username and password).\n",
    "- '@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/' (the host and port).\n",
    "- 'census' (the database name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://' +\n",
    "'student:datacamp' +\n",
    "'@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/'+\n",
    "'census')\n",
    "\n",
    "# Print the table names\n",
    "print(engine.table_names())\n",
    "\n",
    "# output\n",
    "['census', 'state_fact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Calculating a Difference between Two Columns\n",
    "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
    "\n",
    "You can use these operators to perform addition (+), subtraction (-), multiplication (*), division (/), and modulus (%) operations. Note: They behave differently when used with non-numeric column types.\n",
    "\n",
    "Let's now find the top 5 states by population growth between 2000 and 2008. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query to return state names by population difference from \n",
    "# 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state,\n",
    "(census.columns.pop2008-census.columns.pop2000).label('pop_change')])\n",
    "\n",
    "# Append group by for the state: stmt\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt\n",
    "stmt = stmt.limit(5)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))\n",
    "    \n",
    "# output\n",
    "California:105705\n",
    "Florida:100984\n",
    "Texas:51901\n",
    "New York:47098\n",
    "Pennsylvania:42387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Determining the Overall Percentage of Females\n",
    "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the case() expression to operate on data that meets specific criteria while not affecting the query as a whole. The case() expression accepts a list of conditions to match and the column to return if the condition matches, followed by an else_ if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
    "\n",
    "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the cast() function to convert an expression to a particular type.\n",
    "\n",
    "Build an expression female_pop2000to calculate female population in 2000. To achieve this:\n",
    "    - Use case() inside func.sum().\n",
    "    - The first argument of case() is a list containing a tuple of\n",
    "        - i) A boolean checking that census.columns.sex is equal to 'F'.\n",
    "        - ii) The column census.columns.pop2000.\n",
    "    - The second argument is the else_ condition, which should be set to 0.\n",
    "- Calculate the total population in 2000 and use cast() to convert it to Float.\n",
    "- Build a query to calculate the percentage of females in 2000. To do this, divide female_pop2000 by total_pop2000 and multiply by 100.\n",
    "- Execute the query and print percent_female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "    case([\n",
    "        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000* 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)\n",
    "\n",
    "# output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 SQL relationships\n",
    "Relationships\n",
    "- allow us to avoid duplicate data\n",
    "- make it easy to change things in one place\n",
    "- useful to break out info from a table we don't need very often\n",
    "\n",
    "Join\n",
    "- accepts a Table and an optional expression that explains how the two tables are related\n",
    "- the expression is not needed if the relationship is predefined and available via reflection\n",
    "- comes immediately after the select() clause, prior to any where(), order_by or group_by() clauses\n",
    "\n",
    "Select_from\n",
    "- used to replace the default, derived FROM clause with a join\n",
    "- wraps the join() clause\n",
    "\n",
    "Joining Tables without Predefined Relationship\n",
    "- join accepts a Table and an optional expression that explains how the two tables are related\n",
    "- will only join on data that match between the two columns\n",
    "- avoid joining on columns of different types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 Automatic Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select([census.columns.pop2008,\n",
    "               state_fact.columns.abbreviation\n",
    "              ])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.6.2 Select_from example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "# join census table with state_fact table\n",
    "stmt = stmt.select_from(census.join(state_fact))\n",
    "# subset based on condition\n",
    "stmt = stmt.where(state_fact.columns.circuit_court == '10')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 Select_from example - join tables w/o predefined relationship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "# join census table with state_fact table\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state\n",
    "               == state_fact.columns.name))\n",
    "stmt = stmt.where(state_fact.columns.census_division_name == \n",
    "                  'Ease South Central')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.4 Automatic Joins with an Established Relationship\n",
    "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query:\n",
    "\n",
    "- stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])\n",
    "\n",
    "in order to join the census and state_fact tables and select the pop2008 column from the first and the abbreviation column from the second. In this case, the census and state_fact tables had a pre-defined relationship: the state column of the former corresponded to the name column of the latter.\n",
    "\n",
    "In this exercise, you'll use the same predefined relationship to select the pop2000 and abbreviation columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, \n",
    "state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))\n",
    "\n",
    "# output\n",
    "pop2000 89600\n",
    "abbreviation IL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.5 Joins\n",
    "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the .join() method on a table to join it with another table and get extra data related to our query. The join() takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the .select_from() method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the census table to the state_fact table such that the state column of the census table corresponded to the name column of the state_fact table.\n",
    "\n",
    "- stmt = stmt.select_from(\n",
    "    census.join(\n",
    "    state_fact, census.columns.state == \n",
    "    state_fact.columns.name)\n",
    "    \n",
    "    \n",
    "- Build a statement to select ALL the columns from the census and state_fact tables. To select ALL the columns from two tables employees and sales, for example, you would use stmt = select([employees, sales]).\n",
    "- Append a select_from to stmt to join the census table to the state_fact table by the state column in census and the name column in the state_fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.6 More Practice with Joins\n",
    "You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a group_by() clause.\n",
    "\n",
    "- Build a statement to select:\n",
    "    - The state column from the census table.\n",
    "    - The sum of the pop2008 column from the census table.\n",
    "    - The census_division_name column from the state_fact table.\n",
    "- Append a .select_from() to stmt in order to join the census and state_fact tables by the state and name columns.\n",
    "- Group the statement by the name column of the state_fact table.\n",
    "- Execute the statement to get all the records and save it as results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and \n",
    "# census\n",
    "# division name: stmt\n",
    "stmt = select([\n",
    "    census.columns.state,\n",
    "    func.sum(census.columns.pop2008),\n",
    "    state_fact.columns.census_division_name\n",
    "])\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the \n",
    "# census state and state_fact name columns\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, \n",
    "                census.columns.state == state_fact.columns.name)\n",
    ")\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt = stmt.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)\n",
    "    \n",
    "<script.py> output:\n",
    "    ('Alabama', 4649367, 'East South Central')\n",
    "    ('Alaska', 664546, 'Pacific')\n",
    "    ('Arizona', 6480767, 'Mountain')\n",
    "    # ...etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Working with Hierarchical Tables - tables that join with themselves\n",
    "\n",
    "Hierarchical Tables\n",
    "- contain a relationship with themselves\n",
    "- commonly found in:\n",
    "    - organizational\n",
    "    - geographic\n",
    "    - network\n",
    "    - graph\n",
    "    \n",
    "Hierarchical Tables - alias()\n",
    "- requires a way to view the table via multiple names\n",
    "- creates a unique reference that we can use\n",
    "\n",
    "Group_by and Func\n",
    "- it's important to target group_by() at the right alias\n",
    "- be careful with what you perform functions on\n",
    "- if you don't find yourself using both the alias and the table name for a query, don't create the alias at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Querying Hierarchical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = employees.alias()\n",
    "stmt = select(\n",
    "        [managers.columns.name.label('manager'),\n",
    "        employees.columns.name.label('employee')]\n",
    ")\n",
    "# use alias to join\n",
    "stmt = stmt.select_from(employees.join(\n",
    "managers, managers.columns.id == employees.columns.manager))\n",
    "# order by manager name\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Hierarchical data - group_by and func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = employees.alias()\n",
    "stmt = select([managers.columns.name,\n",
    "               func.sum(employees.columns.sal)])\n",
    "# use alias to join\n",
    "stmt = stmt.select_from(employees.join(\n",
    "managers, managers.columns.id == employees.columns.manager))\n",
    "# order by manager name\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.3 Using alias to handle same table joined queries\n",
    "Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The .alias() method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
    "\n",
    "Here, you'll use the .alias() method to build a query to join the employees table against itself to determine to whom everyone reports.\n",
    "\n",
    "- Save an alias of the employees table as managers. To do so, apply the method .alias() to employees.\n",
    "- Build a query to select the employee name and their manager's name. The manager's name has already been selected for you. Use label to label the name column of employees as 'employee'.\n",
    "- Append a where clause to stmt to match where the id column of the managers table corresponds to the mgr column of the employees table.\n",
    "- Order the statement by the name column of the managers table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select manager's and their employees names: stmt\n",
    "stmt = select(\n",
    "    [managers.columns.name.label('manager'),\n",
    "     employees.columns.name.label('employee')]\n",
    ")\n",
    "\n",
    "# Match managers id with employees mgr: stmt\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Order the statement by the managers name: stmt\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.4 Leveraging Functions and Group_bys with Hierarchical Data\n",
    "It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function.\n",
    "\n",
    "Here, your job is to get a count of employees for each manager.\n",
    "\n",
    "- Build a query to select the name column of the managers table and the count of the number of their employees. The function func.count() has been imported and will be useful! Use it to count the id column of the employees table.\n",
    "- Using a .where() clause, filter the records where the id column of the managers table and mgr column of the employees table are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select managers and counts of their employees: stmt\n",
    "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Dealing with Large ResultSets\n",
    "- fetchmany() lets us specify how many rows we want to act upon\n",
    "- we can loop over fetchmany()\n",
    "- it returns an empty list when there are no more records\n",
    "- required: call close method on ResultProxy afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Fetching many rows - .fetchmany()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while more_results:\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "        \n",
    "    for row in partial_results:\n",
    "        state_count[row.state] += 1\n",
    "    \n",
    "results_proxy.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 Working on Blocks of Records\n",
    "Fantastic work so far! As Jason discussed in the video, sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the .fetchmany() method inside a loop. With .fetchmany(), give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the .close() method to close out the connection to the database.\n",
    "\n",
    "You'll now have the chance to practice this on a large ResultProxy called results_proxy that has been pre-loaded for you to work with.\n",
    "\n",
    "- Loop over the partial_results and, if row.state is a key in the state_count dictionary, increment state_count[row.state] by 1; otherwise set state_count[row.state] to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state] += 1\n",
    "        else:\n",
    "            state_count[row.state] = 1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "print(state_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating and Manipulating your own Databases and Tables\n",
    "Creating Databases\n",
    "- varies by the db type\n",
    "- db like PostgreSQL and MySQL have command line tools to initialize the database\n",
    "- with SQLite, the create_engine() statement will create the db and file if they do not already exist\n",
    "\n",
    "Creating Tables\n",
    "- still uses the Table object like we did for reflection\n",
    "- replaces the autoload keyword arguments with Column objects\n",
    "- creates the tables in the actual db by using the create_all() method on the MetaData instance\n",
    "- You need to use other tools to handle db table updates, such as Alembic or raw SQL\n",
    "\n",
    "Creating Tables - Additional Column Options\n",
    "- unique - forces all values for the data in a column to be unique\n",
    "- nullable - determines if a column can be empty in a row\n",
    "- default - sets a default value if one isn't supplied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Building a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import different data types\n",
    "from sqlalchemy import (Table, Column, String, Integer, Decimal, \n",
    "                        Boolean)\n",
    "# create a Table object\n",
    "employees = Table('employees', metadata,\n",
    "                 Column('id', Integer()),\n",
    "                 Column('name', String(255)),\n",
    "                 Column('salary', Decimal()),\n",
    "                 Column('active', Boolean()))\n",
    "\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# verify that the table was created\n",
    "engine.table_names()\n",
    "[u'employees']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Building a Table with Additional Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = Table('employees', metadata,\n",
    "                 Column('id', Integer()),\n",
    "                 Column('name', String(255), unique=True, \n",
    "                        nullable=False),\n",
    "                 Column('salary', Float(), default=100.00),\n",
    "                 Column('active', Boolean(), default=True))\n",
    "\n",
    "# check constraints and defaults\n",
    "employees.constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Creating Tables with SQLAlchemy\n",
    "Previously, you used the Table object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the Table object; however, you'd need to replace the autoload and autoload_with parameters with Column objects.\n",
    "\n",
    "The Column object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints.\n",
    "\n",
    "When defining the table, recall how in the video Jason passed in 255 as the maximum length of a String by using Column('name', String(255)). Checking out the slides from the video may help: you can download them by clicking on 'Slides' next to the IPython Shell.\n",
    "\n",
    "After defining the table, you can create the table in the database by using the .create_all() method on metadata and supplying the engine as the only parameter. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from \n",
    "# sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, \n",
    "Boolean\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: \n",
    "# data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255)),\n",
    "             Column('count', Integer()),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean())\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table details\n",
    "print(repr(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Constraints and Data Defaults\n",
    "You're now going to practice creating a table with some constraints! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in.\n",
    "\n",
    "As Jason showed you in the video, in addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from \n",
    "# sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, \n",
    "Boolean\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: \n",
    "# data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255), unique=True),\n",
    "             Column('count', Integer(), default=1),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean(), default=False)\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['data']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Inserting Data into a Table\n",
    "Adding Data to a Table\n",
    "- done with the insert() statement\n",
    "- insert() takes the table we are loading data into as the argument\n",
    "- we add all the values we want to insert in with the values clause as column=value pairs\n",
    "- doesn't return any rows, so no need for a fetch method\n",
    "\n",
    "Inserting Multiple Rows\n",
    "- build an insert statement without any values\n",
    "- build a list of dictionaries that represent all the values clauses for the rows you want to insert\n",
    "- pass both the stmt and the values list to the execute method on connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Insert one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "stmt = insert(employees).values(id=1, name='Jason',\n",
    "                               salary=1.00, active=True)\n",
    "result_proxy = connection.exectue(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Insert multiple rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = insert(employees)\n",
    "# one dictionary for each record you want to insert\n",
    "values_list = [\n",
    "    {'id':2, 'name':'Rebecca', 'salary':2.00, 'active'=True},\n",
    "    {'id':3, 'name':'Bob', 'salary':0.00, 'active'=False}\n",
    "]\n",
    "result_proxy = connection.execute(stmt, values_list)\n",
    "print(result_proxy.rowcount)\n",
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 1: Inserting a single row with an insert() statement\n",
    "There are several ways to perform an insert with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement.\n",
    "\n",
    "It uses an insert statement where you specify the table as an argument, and supply the data you wish to insert into the value via the .values() method as keyword arguments.\n",
    "\n",
    "Here, the name of the table is data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import insert and select from sqlalchemy\n",
    "from sqlalchemy import insert, select\n",
    "\n",
    "# Build an insert statement to insert a record into the \n",
    "# data table: stmt\n",
    "stmt = insert(data).values(name='Anna', count=1, amount=1000.00, \n",
    "                           valid=True)\n",
    "\n",
    "# Execute the statement via the connection: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a select statement to validate the insert\n",
    "stmt = select([data]).where(data.columns.name == 'Anna')\n",
    "\n",
    "# Print the result of executing the query.\n",
    "print(connection.execute(stmt).first())\n",
    "\n",
    "<script.py> output:\n",
    "    1\n",
    "    ('Anna', 1, 1000.0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 2: Inserting Multiple Records at Once\n",
    "It's time to practice inserting multiple records at once!\n",
    "\n",
    "As Jason showed you in the video, you'll want to first build a list of dictionaries that represents the data you want to insert. Then, in the .execute() method, you can pair this list of dictionaries with an insert statement, which will insert all the records in your list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of dictionaries: values_list\n",
    "values_list = [\n",
    "    {'name': 'Anna', 'count': 1, 'amount': 1000.00, 'valid': True},\n",
    "    {'name': 'Taylor', 'count': 1, 'amount': 750.00, 'valid': False}\n",
    "]\n",
    "\n",
    "# Build an insert statement for the data table: stmt\n",
    "stmt = insert(data)\n",
    "\n",
    "# Execute stmt with the values_list: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Loading a CSV into a Table\n",
    "We have used the csv module to set up a csv_reader, which is just a reader object that can iterate over the lines in a given CSV file - in this case, a census CSV file. Using the enumerate() function, you can loop over the csv_reader to handle the results one at a time. Here, for example, the first line it would return is:\n",
    "\n",
    "0 ['Illinois', 'M', '0', '89600', '95012']\n",
    "\n",
    "0 is the idx - or line number - while ['Illinois', 'M', '0', '89600', '95012'] is the row, corresponding to the column names 'state' , 'sex', 'age', 'pop2000 'and 'pop2008'. 'Illinois' can be accessed with row[0], 'M' with row[1], and so on. You can create a dictionary containing this information where the keys are the column names and the values are the entries in each line. Then, by appending this dictionary to a list, you can combine it with an insert statement to load it all into a table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a insert statement for census: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Create an empty list and zeroed row count: values_list, total_rowcount\n",
    "values_list = []\n",
    "total_rowcount = 0\n",
    "\n",
    "# Enumerate the rows of csv_reader\n",
    "for idx, row in enumerate(csv_reader):\n",
    "    #create data and append to values_list\n",
    "    data = {'state': row[0], 'sex': row[1], 'age': row[2], 'pop2000': row[3],\n",
    "            'pop2008': row[4]}\n",
    "    values_list.append(data)\n",
    "\n",
    "    # Check to see if divisible by 51\n",
    "    if idx % 51 == 0:\n",
    "        results = connection.execute(stmt, values_list)\n",
    "        total_rowcount += results.rowcount\n",
    "        values_list = []\n",
    "\n",
    "# Print total rowcount\n",
    "print(total_rowcount)\n",
    "\n",
    "# 8722"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Updating Data in a Table\n",
    "- done with the update statement\n",
    "- similar to the insert statement but includes a where clause to determine what record will be updated\n",
    "- we add all the values we want to update with the values clause as column=value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Updating One Row - update + where clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import update\n",
    "stmt = update(employees)\n",
    "stmt = stmt.where(employees.columns.id ==3)\n",
    "stmt = stmt.values(active=True)\n",
    "result_proxy = connection.execute(stmt)\n",
    "\n",
    "# check only 1 row was updated\n",
    "print(result_proxy.rowcount)\n",
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Updating Multiple Rows\n",
    "- build a where clause that will select all the records you want to update\n",
    "- check to make sure you updated the correct number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = update(employees)\n",
    "stmt = stmt.where(employees.columns.active == True)\n",
    "# update active and salary columns\n",
    "stmt = stmt.values(active=False, salary=0.00)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Correlated Updates\n",
    "- Uses a select() statement to find the value for the column we are updating\n",
    "- commonly used to update records to a maximum value or change a string to match an abbreviation from another table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to pay all employees the same amount\n",
    "\n",
    "new_salary = select([employees.columns.salary])\n",
    "\n",
    "# get maximum salary\n",
    "new_salary = new_salary.order_by(desc(employees.columns.salary))\n",
    "new_salary = new_salary.limit(1)\n",
    "\n",
    "# update every record\n",
    "stmt = update(employees)\n",
    "# set salary to select statment - which is max salary\n",
    "stmt = stmt.values(salary=new_salary)\n",
    "result_proxy = connection.execute(stmt)\n",
    "print(result_proxy.rowcount)\n",
    "# 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4.a Example 1: Updating individual records - update + where\n",
    "The update statement is very similar to an insert statement, except that it also typically uses a where clause to help us determine what data to update. \n",
    "\n",
    "You'll be using the FIPS state code using here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas. Recall that you can update all wages in the employees table as follows:\n",
    "\n",
    "stmt = update(employees).values(wage=100.00)\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name (Column), and fips_state (Column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a select statement: select_stmt\n",
    "select_stmt = select([state_fact]).where(\n",
    "    state_fact.columns.name == 'New York')\n",
    "\n",
    "# Print the results of executing the select_stmt\n",
    "print(connection.execute(select_stmt).fetchall())\n",
    "\n",
    "# Build a statement to update the fips_state to 36: stmt\n",
    "stmt = update(state_fact).values(fips_state = 36)\n",
    "\n",
    "# Append a where clause to limit it to records for New York state\n",
    "stmt = stmt.where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Execute the select_stmt again to view the changes\n",
    "print(connection.execute(select_stmt).fetchall())\n",
    "\n",
    "# output\n",
    "[('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', \n",
    "  '', '0', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]\n",
    "1\n",
    "[('32', 'New York', 'NY', 'USA', 'state', '10', 'current', 'occupied', \n",
    "  '', '36', 'N.Y.', 'II', '1', 'Northeast', '2', 'Mid-Atlantic', '2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4.b Example 2: Updating Multiple Records\n",
    "By using a where clause that selects more records, you can update multiple records at once.\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), notes (Column), and census_region_name (Column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to update the notes to 'The Wild West': stmt\n",
    "stmt = update(state_fact).values(notes='The Wild West')\n",
    "\n",
    "# Append a where clause to match the West census region records\n",
    "stmt = stmt.where(state_fact.columns.census_region_name == 'West')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# output\n",
    "# 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4.c Example 3: Correlated Updates\n",
    "You can also update records with data from a select statement. This is called a correlated update. It works by defining a select statement that returns the value you want to update the record with and assigning that as the value in an update statement.\n",
    "\n",
    "You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table.\n",
    "\n",
    "- Build a statement to select the name column from state_fact. Save the statement as fips_stmt.\n",
    "- Append a where clause to fips_stmt that matches fips_state from the state_fact table with fips_code in the flat_census table.\n",
    "- Build an update statement to set the state_name in flat_census to fips_stmt. Save the statement as update_stmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T03:18:30.812981Z",
     "start_time": "2018-10-08T03:18:30.736165Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a statement to select name from state_fact: stmt\n",
    "fips_stmt = select([state_fact.columns.name])\n",
    "\n",
    "# Append a where clause to Match the fips_state to flat_census fips_code\n",
    "fips_stmt = fips_stmt.where(\n",
    "    state_fact.columns.fips_state == flat_census.columns.fips_code)\n",
    "\n",
    "# Build an update statement to set the name to fips_stmt: update_stmt\n",
    "update_stmt = update(flat_census).values(state_name=fips_stmt)\n",
    "\n",
    "# Execute update_stmt: results\n",
    "results = connection.execute(update_stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# output\n",
    "# 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Removing Data from a Database\n",
    "- Done with the delete() statement\n",
    "- delete() takes the table we are loading data into as the argument\n",
    "- a where() clause is used to choose which rows to delete\n",
    "- hard to undo, so BE CAREFUL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 Deleting all Data from a Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import delete\n",
    "stmt = select([func.count(extra_employees.columns.id)])\n",
    "# check number of records selected\n",
    "connection.execute(stmt).scalar()\n",
    "# 3\n",
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)\n",
    "result_proxy.rowcount\n",
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 Deleting Specific Rows\n",
    "- build a where clause that will select all the records you want to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = delete(employees).where(employees.columns.id ==3)\n",
    "result_proxy = connection.execute(stmt)\n",
    "result_proxy.rowcount\n",
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 Dropping a Table Completely\n",
    "- uses the drop method on the table\n",
    "- accepts the engine as an argument so it knows where to remove the table from\n",
    "- won't remove it from metadata until the python process it restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_employees.drop(engine)\n",
    "# verify that it was deleted by seeing if it still exists\n",
    "print(extra_employees.exists(engine))\n",
    "# false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.4 Dropping all the Tables\n",
    "- Uses the drop_all() method on MetaData\n",
    "- completely empty the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop_all(engine)\n",
    "engine.table_names()\n",
    "# []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.5 Practice examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5.a Deleting all the records from a table\n",
    "Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a delete statement with just the table as an argument. For example, in the video, Jason deleted the table extra_employees by executing as follows:\n",
    "\n",
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)\n",
    "Do be careful, though, as deleting cannot be undone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delete, select\n",
    "from sqlalchemy import delete, select\n",
    "\n",
    "# Build a statement to empty the census table: stmt\n",
    "stmt = delete(census)\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print affected rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a statement to select all records from the census table\n",
    "stmt = select([census])\n",
    "\n",
    "# Print the results of executing the statement to verify there are \n",
    "# no rows\n",
    "print(connection.execute(stmt).fetchall())\n",
    "\n",
    "# output\n",
    "8772\n",
    "[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5.b Deleting specific records\n",
    "By using a where() clause, you can target the delete statement to remove only certain records. For example, Jason deleted all rows from the employees table that had id 3 with the following delete statement:\n",
    "\n",
    "delete(employees).where(employees.columns.id == 3) \n",
    "Here you'll delete ALL rows which have 'M' in the sex column and 36 in the age column. We have included code at the start which computes the total number of these rows. It is important to make sure that this is the number of rows that you actually delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to count records using the sex column for \n",
    "# Men ('M') age 36: stmt\n",
    "stmt = select([func.count(census.columns.sex)]).where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the select statement and use the scalar() fetch method to \n",
    "# save the record count\n",
    "to_delete = connection.execute(stmt).scalar()\n",
    "\n",
    "# Build a statement to delete records from the census table: stmt_del\n",
    "stmt_del = delete(census)\n",
    "\n",
    "# Append a where clause to target Men ('M') age 36\n",
    "stmt_del = stmt_del.where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt_del)\n",
    "\n",
    "# Print affected rowcount and to_delete record count, make sure they \n",
    "# match\n",
    "print(results.rowcount, to_delete)\n",
    "\n",
    "# output\n",
    "51 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5.c Deleting a Table Completely\n",
    "You're now going to practice dropping individual tables from a database with the .drop() method, as well as all tables in a database with the .drop_all() method!\n",
    "\n",
    "As Spider-Man's Uncle Ben (as well as Jason, in the video!) said: With great power, comes great responsibility. Do be careful when deleting tables, as it's not simple or fast to restore large databases! Remember, you can check to see if a table exists with the .exists() method.\n",
    "\n",
    "This is the final exercise in this chapter: After this, you'll be ready to apply everything you've learned to a case study in the final chapter of this course!\n",
    "\n",
    "- Drop the state_fact table by applying the method .drop() to it and passing it the argument engine (in fact, engine will be the sole argument for every function/method in this exercise!)\n",
    "- Check to see if state_fact exists via print. Use the .exists() method with engine as the argument.\n",
    "- Drop all the tables via the metadata using the .drop_all() method.\n",
    "- Use a print statement to check if the census table exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the state_fact table\n",
    "state_fact.drop(engine)\n",
    "\n",
    "# Check to see if state_fact exists\n",
    "print(state_fact.exists(engine))\n",
    "\n",
    "# Drop all tables\n",
    "metadata.drop_all(engine)\n",
    "\n",
    "# Check to see if census exists\n",
    "print(census.exists(engine))\n",
    "\n",
    "# output\n",
    "False\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Project: Putting it all together\n",
    "Census Case study - 3 parts\n",
    "- Part 1: Preparing SQLAlchemy and the Database\n",
    "- Part 2: Loading Data into the Database\n",
    "- Part 3: Solving Data Science Problems with Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Part 1: Preparing SQLAlchemy and the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Engine and MetaData object\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "metadata = MetaData()\n",
    "\n",
    "# create and save the census table\n",
    "from sqlalchemy import (Table, Column, String, Integer, Decimal, Boolean)\n",
    "employees = Table('employees', metadata,\n",
    "                  Column('id', Integer()),\n",
    "                  Column('name', String(255)),\n",
    "                  Column('salary', Decimal()),\n",
    "                  Column('active', Boolean())\n",
    "                 )\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.a Practice: Setup the Engine and MetaData\n",
    "In this exercise, your job is to create an engine to the database that will be used in this chapter. Then, you need to initialize its metadata.\n",
    "\n",
    "Recall how you did this in Chapter 1 by leveraging create_engine() and MetaData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "\n",
    "# Define an engine to connect to chapter5.sqlite: engine\n",
    "engine = create_engine('sqlite:///chapter5.sqlite')\n",
    "\n",
    "# Initialize MetaData: metadata\n",
    "metadata = MetaData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.b Create the Table to the Database\n",
    "Having setup the engine and initialized the metadata, you will now define the census table object and then create it in the database using the metadata and engine from the previous exercise. To create it in the database, you will have to use the .create_all() method on the metadata with engine as the argument.\n",
    "\n",
    "It may help to refer back to the Chapter 4 exercise in which you learned how to create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table, Column, String, and Integer\n",
    "from sqlalchemy import (Table, Column, String, Integer)\n",
    "\n",
    "# Build a census table: census\n",
    "census = Table('census', metadata,\n",
    "               Column('state', String(30)),\n",
    "               Column('sex', String(1)),\n",
    "               Column('age', Integer()),\n",
    "               Column('pop2000', Integer()),\n",
    "               Column('pop2008', Integer()))\n",
    "\n",
    "# Create the table in the database\n",
    "metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Part 2: Populating the Database\n",
    "- load a csv file into a values list\n",
    "- insert the values list into the census table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a csv file into a values list\n",
    "# empty list\n",
    "values_list = []\n",
    "# loop over rows of csv and use dictionary to load\n",
    "for row in csv_reader:\n",
    "    data = {'state':row[0], 'sex':row[1], 'age':row[2],\n",
    "            'pop2000':row[3], 'pop2008':row[4]}\n",
    "    values_list.append(data)\n",
    "\n",
    "# insert the values list into the census table\n",
    "from sqlalchemy import insert\n",
    "stmt = insert(employees)\n",
    "result_proxy = connection.execute(stmt, values_list)\n",
    "print(result_proxy.rowcount)\n",
    "# 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.a Practice: Reading the Data from the CSV\n",
    "Leverage the Python CSV module from the standard library and load the data into a list of dictionaries.\n",
    "\n",
    "It may help to refer back to the Chapter 4 exercise in which you did something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list: values_list\n",
    "values_list = []\n",
    "\n",
    "# Iterate over the rows\n",
    "for row in csv_reader:\n",
    "    # Create a dictionary with the values\n",
    "    data = {'state': row[0], 'sex': row[1], 'age':row[2], \n",
    "            'pop2000': row[3], 'pop2008': row[4]}\n",
    "    # Append the dictionary to the values list\n",
    "    values_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.b Practice: Load Data from a list into the Table\n",
    "Using the multiple insert pattern, in this exercise, you will load the data from values_list into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import insert\n",
    "from sqlalchemy import insert\n",
    "\n",
    "# Build insert statement: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Use values_list to insert data: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Example DB Queries\n",
    "Answering Data Science Questions with Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Determine Average Age for Males and Females "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select\n",
    "stmt = select([census.columns.sex,\n",
    "               (func.sum(census.columns.pop2008 *\n",
    "                        census.columns.age) /\n",
    "                func.sum(census.columns.pop2008)\n",
    "               ).label('average_age')\n",
    "              ])\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "results = connection.execute(stmt).fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Determine the percentage of Females for each state\n",
    "- use Case and Cast clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import case, cast, Float\n",
    "stmt = select([\n",
    "    (func.sum(\n",
    "        case([(census.columns.state == 'New York',\n",
    "               census.columns.pop2008)], else_=0)) /\n",
    "     cast(func.sum(census.columns.pop2008),\n",
    "         Float) * 100).label('ny_percent')    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Determine the top 5 states by population change from 2000 to 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select([census.columns.age,\n",
    "               (census.columns.pop2008 -\n",
    "                census.columns.pop2000).label('pop_change')\n",
    "              ])\n",
    "stmt = stmt.order_by('pop_change')\n",
    "stmt = stmt.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Build a Query to Determine the Average Age by Population\n",
    "In this exercise, you will use the func.sum() and group_by() methods to first determine the average age weighted by the population in 2008, and then group by sex.\n",
    "\n",
    "As Jason discussed in the video, a weighted average is calculated as the sum of the product of the weights and averages divided by the sum of all the weights.\n",
    "\n",
    "For example, the following statement determines the average age weighted by the population in 2000:\n",
    "\n",
    "stmt = select([census.columns.sex,\n",
    "               (func.sum(census.columns.pop2000 * census.columns.age) /\n",
    "                func.sum(census.columns.pop2000)).label('average_age')\n",
    "               ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select\n",
    "from sqlalchemy import select\n",
    "\n",
    "# Calculate weighted average age: stmt\n",
    "stmt = select([census.columns.sex,\n",
    "               (func.sum(census.columns.pop2008 * census.columns.age) /\n",
    "                func.sum(census.columns.pop2008)).label('average_age')\n",
    "               ])\n",
    "\n",
    "# Group by sex\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the average age by sex\n",
    "for result in results:\n",
    "    print(result.sex, result.average_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build a Query to Determine the Percentage of Population by Gender and State\n",
    "In this exercise, you will write a query to determine the percentage of the population in 2000 that comprised of women. You will group this query by state.\n",
    "\n",
    "- Define a statement to select state and the percentage of females in 2000.\n",
    "    - Inside func.sum(), use case() to select females (using the sex column) from pop2000. Remember to specify else_=0 if the sex is not 'F'.\n",
    "    - To get the percentage, divide the number of females in the year 2000 by the overall population in 2000. Cast the divisor - census.columns.pop2000 - to Float before multiplying by 100.\n",
    "- Group the query by state.\n",
    "- Execute the query and store it as results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select([census.columns.state,\n",
    "    (func.sum(\n",
    "        case([\n",
    "            (census.columns.sex == 'F', \n",
    "            census.columns.pop2000)\n",
    "        ], else_=0)) /\n",
    "     cast(func.sum(census.columns.pop2000), Float) * 100).\n",
    "               label('percent_female')\n",
    "])\n",
    "\n",
    "# Group By state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the percentage\n",
    "for result in results:\n",
    "    print(result.state, result.percent_female)\n",
    "\n",
    "# output\n",
    "# Alabama 51.8324077702\n",
    "# Alaska 49.3014978935\n",
    "# Arizona 50.2236130306\n",
    "# ...etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Build a Query to Determine the Population Difference by State from the 2000 and 2008 Censuses\n",
    "In this final exercise, you will write a query to calculate the states that changed the most in population. You will limit your query to display only the top 10 states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query to return state name and population difference from \n",
    "# 2008 to 2000\n",
    "stmt = select([census.columns.state,\n",
    "     (census.columns.pop2008-census.columns.pop2000).label('pop_change')\n",
    "])\n",
    "\n",
    "# Group by State\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Order by Population Change\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Limit to top 10\n",
    "stmt = stmt.limit(10)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))\n",
    "\n",
    "# output\n",
    "# California:105705\n",
    "# Florida:100984\n",
    "# Texas:51901\n",
    "# New York:47098\n",
    "# Pennsylvania:42387\n",
    "# Arizona:29509\n",
    "# Ohio:29392\n",
    "# Illinois:26221\n",
    "# Michigan:25126\n",
    "# North Carolina:24108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
